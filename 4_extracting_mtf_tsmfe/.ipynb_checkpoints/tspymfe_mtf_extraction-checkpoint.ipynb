{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CompEngine dataset analysis\n",
    "## Analysis #4: Get TS-Pymfe meta-features accuracy\n",
    "\n",
    "**Project URL:** https://www.comp-engine.org/\n",
    "\n",
    "**Get data in:** https://www.comp-engine.org/#!browse\n",
    "\n",
    "**Date:** May 31 2020\n",
    "\n",
    "### Objectives:\n",
    "1. Extract the meta-features using the ts-pymfe from train and test data\n",
    "2. Drop metafeatures with NaN.\n",
    "3. Apply PCA in the train meta-dataset.\n",
    "4. Use a simple machine learning model to predict the test set.\n",
    "\n",
    "### Results (please check the analysis date):\n",
    "1. All metafeatures from all methods combined with all summary functions in pymfe were extracted from both train and test data. This totalizes 5165 candidate meta-features.\n",
    "2. ??\n",
    "3. The next step is to apply PCA retaining 95% of variance explained by the original meta-features. Before applying PCA we need to choose a normalization strategy. Two methods were considered:\n",
    "    1. (Pipeline A) Standard Scaler (traditional standardization): ?? of ?? dimensions were kept. This corresponds to a dimension reduction of ??%.\n",
    "    2. (Pipeline B) Robust Sigmoid Scaler (see reference [1]): ?? of ?? dimensions were kept. This corresponds to a dimension reduction of ??%.\n",
    "4. Now it is time for some predictions. I'm using a sklearn RandomForestClassifier model with default hyper-parameters with a fixed random seed.\n",
    "    1. The expected accuracy of random guessing is 2.17%.\n",
    "    2. (Pipeline A) It was obtained an accuracy score of ??%.\n",
    "    3. (Pipeline B) It was obtained an accuracy score of ??%.\n",
    "    \n",
    "\n",
    "## references:\n",
    "\n",
    ".. [1] Fulcher, Ben D.  and Little, Max A.  and Jones, Nick S., \"Highly comparative time-series analysis: the empirical structure of time series and their methods\" (Supplemental material #1, page 11), Journal of The Royal Society Interface, 2013, doi: 10.1098/rsif.2013.0048, https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2013.0048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import typing\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "\n",
    "import robust_sigmoid\n",
    "import pymfe.tsmfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: using only groups that has at least one meta-feature that can be extracted\n",
    "# from a unsupervised dataset\n",
    "groups = \"all\"\n",
    "summary = \"all\"\n",
    "\n",
    "extractor = pymfe.tsmfe.TSMFE(features=\"all\",\n",
    "                              summary=summary,\n",
    "                              groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../2_exploring_subsample/subsample_train.csv\", header=0, index_col=\"timeseries_id\")\n",
    "data_test = pd.read_csv(\"../2_exploring_subsample/subsample_test.csv\", header=0, index_col=\"timeseries_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>inst_ind</th>\n",
       "      <th>datapoints</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeseries_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e0b36e39-3872-11e8-8680-0242ac120002</th>\n",
       "      <td>Beta noise</td>\n",
       "      <td>25254</td>\n",
       "      <td>0.73617,0.99008,0.71331,0.87094,0.75527,0.9912...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81db0cf2-3883-11e8-8680-0242ac120002</th>\n",
       "      <td>Relative humidity</td>\n",
       "      <td>14878</td>\n",
       "      <td>95.5,79,86.75,8.75,62.75,98.75,79.74,44.75,92....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380eb353-387a-11e8-8680-0242ac120002</th>\n",
       "      <td>RR</td>\n",
       "      <td>6577</td>\n",
       "      <td>0.6328,0.6328,0.625,0.6328,0.625,0.625,0.6172,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f33f461c-3871-11e8-8680-0242ac120002</th>\n",
       "      <td>Tremor</td>\n",
       "      <td>27821</td>\n",
       "      <td>-0.6,1.5,1.5,0.1,0.9,0.6,0.3,-0.2,0.7,1,0.1,1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7bcad309-3874-11e8-8680-0242ac120002</th>\n",
       "      <td>Noisy sinusoids</td>\n",
       "      <td>14226</td>\n",
       "      <td>0.38553,0.2014,1.8705,0.47883,0.33958,0.009558...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               category  inst_ind  \\\n",
       "timeseries_id                                                       \n",
       "e0b36e39-3872-11e8-8680-0242ac120002         Beta noise     25254   \n",
       "81db0cf2-3883-11e8-8680-0242ac120002  Relative humidity     14878   \n",
       "380eb353-387a-11e8-8680-0242ac120002                 RR      6577   \n",
       "f33f461c-3871-11e8-8680-0242ac120002             Tremor     27821   \n",
       "7bcad309-3874-11e8-8680-0242ac120002    Noisy sinusoids     14226   \n",
       "\n",
       "                                                                             datapoints  \n",
       "timeseries_id                                                                            \n",
       "e0b36e39-3872-11e8-8680-0242ac120002  0.73617,0.99008,0.71331,0.87094,0.75527,0.9912...  \n",
       "81db0cf2-3883-11e8-8680-0242ac120002  95.5,79,86.75,8.75,62.75,98.75,79.74,44.75,92....  \n",
       "380eb353-387a-11e8-8680-0242ac120002  0.6328,0.6328,0.625,0.6328,0.625,0.625,0.6172,...  \n",
       "f33f461c-3871-11e8-8680-0242ac120002  -0.6,1.5,1.5,0.1,0.9,0.6,0.3,-0.2,0.7,1,0.1,1....  \n",
       "7bcad309-3874-11e8-8680-0242ac120002  0.38553,0.2014,1.8705,0.47883,0.33958,0.009558...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert data_train.shape[0] > data_test.shape[0]\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: Mean of empty slice.\n",
      " * Warning: invalid value encountered in double_scalars\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice.\n",
      " * Warning: invalid value encountered in double_scalars\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice.\n",
      " * Warning: invalid value encountered in double_scalars\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
      " * Warning: Mean of empty slice.\n",
      " * Warning: invalid value encountered in double_scalars\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice.\n",
      " * Warning: invalid value encountered in double_scalars\n",
      " * Warning: Mean of empty slice\n",
      " * Warning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "# Note: using at most the last 1024 observations of each time-series\n",
    "size_threshold = 1024\n",
    "\n",
    "# Number of iterations until to save results to .csv\n",
    "to_csv_it_num = 8\n",
    "\n",
    "# Note: using dummy data to get the metafeature names\n",
    "mtf_names = extractor.fit(np.random.randn(128),\n",
    "                          ts_period=1,\n",
    "                          suppress_warnings=True).extract(suppress_warnings=True)[0]\n",
    "\n",
    "# Note: filepath to store the results\n",
    "filename_train = \"metafeatures_tspymfe_train.csv\"\n",
    "filename_test = \"metafeatures_tspymfe_test.csv\"\n",
    "\n",
    "def recover_data(filepath: str,\n",
    "                 index: typing.Collection[str],\n",
    "                 def_shape: typing.Tuple[int, int]) -> typing.Tuple[pd.DataFrame, int]:\n",
    "    \"\"\"Recover data from the previous experiment run.\"\"\"\n",
    "    filled_len = 0\n",
    "    \n",
    "    try:\n",
    "        results = pd.read_csv(filepath, index_col=0)\n",
    "        \n",
    "        assert results.shape == def_shape\n",
    "\n",
    "        # Note: find the index where the previous run was interrupted\n",
    "        while filled_len < results.shape[0] and not results.iloc[filled_len, :].isnull().all():\n",
    "            filled_len += 1\n",
    "\n",
    "    except (AssertionError, FileNotFoundError):\n",
    "        results = pd.DataFrame(index=index, columns=mtf_names)\n",
    "    \n",
    "    return results, filled_len\n",
    "\n",
    "\n",
    "results_train, start_ind_train = recover_data(filepath=filename_train,\n",
    "                                              index=data_train.index,\n",
    "                                              def_shape=(data_train.shape[0], len(mtf_names)))\n",
    "\n",
    "results_test, start_ind_test = recover_data(filepath=filename_test,\n",
    "                                            index=data_test.index,\n",
    "                                            def_shape=(data_test.shape[0], len(mtf_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start index: 736\n",
      "Test start index: 184\n"
     ]
    }
   ],
   "source": [
    "assert results_train.shape == (data_train.shape[0], len(mtf_names))\n",
    "assert results_test.shape == (data_test.shape[0], len(mtf_names))\n",
    "\n",
    "print(\"Train start index:\", start_ind_train)\n",
    "print(\"Test start index:\", start_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidate meta-features per dataset: 5165\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of candidate meta-features per dataset:\", len(mtf_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metafeatures(data: pd.DataFrame, results: pd.DataFrame, start_ind: int, output_file: str) -> None:\n",
    "    print(f\"Starting extraction from index {start_ind}...\")\n",
    "    for i, (cls, _, vals) in enumerate(data.iloc[start_ind:, :].values, start_ind):\n",
    "        ts = np.asarray(vals.split(\",\")[-size_threshold:], dtype=float)\n",
    "        extractor.fit(ts, verbose=1, suppress_warnings=True)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            res = extractor.extract(verbose=1, suppress_warnings=True)\n",
    "        \n",
    "        results.iloc[i, :] = res[1]\n",
    "\n",
    "        if i % to_csv_it_num == 0:\n",
    "            results.to_csv(output_file)\n",
    "            print(f\"Saved results at index {i} in file {output_file}.\")\n",
    "    \n",
    "    results.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extraction from index 736...\n",
      "Starting extraction from index 184...\n"
     ]
    }
   ],
   "source": [
    "extract_metafeatures(data=data_train,\n",
    "                     results=results_train,\n",
    "                     start_ind=start_ind_train,\n",
    "                     output_file=filename_train)\n",
    "\n",
    "extract_metafeatures(data=data_test,\n",
    "                     results=results_test,\n",
    "                     start_ind=start_ind_test,\n",
    "                     output_file=filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: analysing the NaN count.\n",
    "results_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "nan_count = results_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of meta-features</th>\n",
       "      <th>Proportion of meta-features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing values count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 (missing on 0.14% of all train time-series)</th>\n",
       "      <td>425</td>\n",
       "      <td>0.082285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254 (missing on 34.51% of all train time-series)</th>\n",
       "      <td>140</td>\n",
       "      <td>0.027106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521 (missing on 70.79% of all train time-series)</th>\n",
       "      <td>89</td>\n",
       "      <td>0.017231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 (missing on 0.41% of all train time-series)</th>\n",
       "      <td>84</td>\n",
       "      <td>0.016263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 (missing on 0.95% of all train time-series)</th>\n",
       "      <td>84</td>\n",
       "      <td>0.016263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 (missing on 1.36% of all train time-series)</th>\n",
       "      <td>84</td>\n",
       "      <td>0.016263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736 (missing on 100.00% of all train time-series)</th>\n",
       "      <td>62</td>\n",
       "      <td>0.012004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105 (missing on 14.27% of all train time-series)</th>\n",
       "      <td>57</td>\n",
       "      <td>0.011036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652 (missing on 88.59% of all train time-series)</th>\n",
       "      <td>56</td>\n",
       "      <td>0.010842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 (missing on 0.27% of all train time-series)</th>\n",
       "      <td>56</td>\n",
       "      <td>0.010842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570 (missing on 77.45% of all train time-series)</th>\n",
       "      <td>52</td>\n",
       "      <td>0.010068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179 (missing on 24.32% of all train time-series)</th>\n",
       "      <td>28</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22 (missing on 2.99% of all train time-series)</th>\n",
       "      <td>28</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17 (missing on 2.31% of all train time-series)</th>\n",
       "      <td>28</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631 (missing on 85.73% of all train time-series)</th>\n",
       "      <td>28</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103 (missing on 13.99% of all train time-series)</th>\n",
       "      <td>26</td>\n",
       "      <td>0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403 (missing on 54.76% of all train time-series)</th>\n",
       "      <td>21</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 (missing on 1.77% of all train time-series)</th>\n",
       "      <td>19</td>\n",
       "      <td>0.003679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97 (missing on 13.18% of all train time-series)</th>\n",
       "      <td>8</td>\n",
       "      <td>0.001549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401 (missing on 54.48% of all train time-series)</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11 (missing on 1.49% of all train time-series)</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603 (missing on 81.93% of all train time-series)</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 (missing on 2.04% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 (missing on 1.09% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96 (missing on 13.04% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37 (missing on 5.03% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106 (missing on 14.40% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127 (missing on 17.26% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128 (missing on 17.39% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148 (missing on 20.11% of all train time-series)</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16 (missing on 2.17% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405 (missing on 55.03% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 (missing on 1.63% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110 (missing on 14.95% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 (missing on 1.22% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560 (missing on 76.09% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271 (missing on 36.82% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406 (missing on 55.16% of all train time-series)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Number of meta-features  \\\n",
       "Missing values count                                                         \n",
       "1 (missing on 0.14% of all train time-series)                          425   \n",
       "254 (missing on 34.51% of all train time-series)                       140   \n",
       "521 (missing on 70.79% of all train time-series)                        89   \n",
       "3 (missing on 0.41% of all train time-series)                           84   \n",
       "7 (missing on 0.95% of all train time-series)                           84   \n",
       "10 (missing on 1.36% of all train time-series)                          84   \n",
       "736 (missing on 100.00% of all train time-series)                       62   \n",
       "105 (missing on 14.27% of all train time-series)                        57   \n",
       "652 (missing on 88.59% of all train time-series)                        56   \n",
       "2 (missing on 0.27% of all train time-series)                           56   \n",
       "570 (missing on 77.45% of all train time-series)                        52   \n",
       "179 (missing on 24.32% of all train time-series)                        28   \n",
       "22 (missing on 2.99% of all train time-series)                          28   \n",
       "17 (missing on 2.31% of all train time-series)                          28   \n",
       "631 (missing on 85.73% of all train time-series)                        28   \n",
       "103 (missing on 13.99% of all train time-series)                        26   \n",
       "403 (missing on 54.76% of all train time-series)                        21   \n",
       "13 (missing on 1.77% of all train time-series)                          19   \n",
       "97 (missing on 13.18% of all train time-series)                          8   \n",
       "401 (missing on 54.48% of all train time-series)                         5   \n",
       "11 (missing on 1.49% of all train time-series)                           5   \n",
       "603 (missing on 81.93% of all train time-series)                         4   \n",
       "15 (missing on 2.04% of all train time-series)                           2   \n",
       "8 (missing on 1.09% of all train time-series)                            2   \n",
       "96 (missing on 13.04% of all train time-series)                          2   \n",
       "37 (missing on 5.03% of all train time-series)                           2   \n",
       "106 (missing on 14.40% of all train time-series)                         2   \n",
       "127 (missing on 17.26% of all train time-series)                         2   \n",
       "128 (missing on 17.39% of all train time-series)                         2   \n",
       "148 (missing on 20.11% of all train time-series)                         2   \n",
       "16 (missing on 2.17% of all train time-series)                           1   \n",
       "405 (missing on 55.03% of all train time-series)                         1   \n",
       "12 (missing on 1.63% of all train time-series)                           1   \n",
       "110 (missing on 14.95% of all train time-series)                         1   \n",
       "9 (missing on 1.22% of all train time-series)                            1   \n",
       "560 (missing on 76.09% of all train time-series)                         1   \n",
       "271 (missing on 36.82% of all train time-series)                         1   \n",
       "406 (missing on 55.16% of all train time-series)                         1   \n",
       "\n",
       "                                                   Proportion of meta-features  \n",
       "Missing values count                                                            \n",
       "1 (missing on 0.14% of all train time-series)                         0.082285  \n",
       "254 (missing on 34.51% of all train time-series)                      0.027106  \n",
       "521 (missing on 70.79% of all train time-series)                      0.017231  \n",
       "3 (missing on 0.41% of all train time-series)                         0.016263  \n",
       "7 (missing on 0.95% of all train time-series)                         0.016263  \n",
       "10 (missing on 1.36% of all train time-series)                        0.016263  \n",
       "736 (missing on 100.00% of all train time-series)                     0.012004  \n",
       "105 (missing on 14.27% of all train time-series)                      0.011036  \n",
       "652 (missing on 88.59% of all train time-series)                      0.010842  \n",
       "2 (missing on 0.27% of all train time-series)                         0.010842  \n",
       "570 (missing on 77.45% of all train time-series)                      0.010068  \n",
       "179 (missing on 24.32% of all train time-series)                      0.005421  \n",
       "22 (missing on 2.99% of all train time-series)                        0.005421  \n",
       "17 (missing on 2.31% of all train time-series)                        0.005421  \n",
       "631 (missing on 85.73% of all train time-series)                      0.005421  \n",
       "103 (missing on 13.99% of all train time-series)                      0.005034  \n",
       "403 (missing on 54.76% of all train time-series)                      0.004066  \n",
       "13 (missing on 1.77% of all train time-series)                        0.003679  \n",
       "97 (missing on 13.18% of all train time-series)                       0.001549  \n",
       "401 (missing on 54.48% of all train time-series)                      0.000968  \n",
       "11 (missing on 1.49% of all train time-series)                        0.000968  \n",
       "603 (missing on 81.93% of all train time-series)                      0.000774  \n",
       "15 (missing on 2.04% of all train time-series)                        0.000387  \n",
       "8 (missing on 1.09% of all train time-series)                         0.000387  \n",
       "96 (missing on 13.04% of all train time-series)                       0.000387  \n",
       "37 (missing on 5.03% of all train time-series)                        0.000387  \n",
       "106 (missing on 14.40% of all train time-series)                      0.000387  \n",
       "127 (missing on 17.26% of all train time-series)                      0.000387  \n",
       "128 (missing on 17.39% of all train time-series)                      0.000387  \n",
       "148 (missing on 20.11% of all train time-series)                      0.000387  \n",
       "16 (missing on 2.17% of all train time-series)                        0.000194  \n",
       "405 (missing on 55.03% of all train time-series)                      0.000194  \n",
       "12 (missing on 1.63% of all train time-series)                        0.000194  \n",
       "110 (missing on 14.95% of all train time-series)                      0.000194  \n",
       "9 (missing on 1.22% of all train time-series)                         0.000194  \n",
       "560 (missing on 76.09% of all train time-series)                      0.000194  \n",
       "271 (missing on 36.82% of all train time-series)                      0.000194  \n",
       "406 (missing on 55.16% of all train time-series)                      0.000194  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_nan_count = nan_count.iloc[nan_count.to_numpy().nonzero()].value_counts()\n",
    "pd_nan_count = pd.concat([pd_nan_count, pd_nan_count / results_train.shape[1]], axis=1)\n",
    "pd_nan_count = pd_nan_count.rename(columns={0: \"Number of meta-features\", 1: \"Proportion of meta-features\"})\n",
    "pd_nan_count.index =  map(\"{} (missing on {:.2f}% of all train time-series)\".format, pd_nan_count.index, 100. * pd_nan_count.index / results_train.shape[0])\n",
    "pd_nan_count.index.name = \"Missing values count\"\n",
    "pd_nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ioe_std_adj_r_sqr', 'ioe_std_slope', 'ioe_tdelta_mean.histogram.0',\n",
      "       'ioe_tdelta_mean.histogram.1', 'ioe_tdelta_mean.histogram.2',\n",
      "       'ioe_tdelta_mean.histogram.3', 'ioe_tdelta_mean.histogram.4',\n",
      "       'ioe_tdelta_mean.histogram.5', 'ioe_tdelta_mean.histogram.6',\n",
      "       'ioe_tdelta_mean.histogram.7', 'ioe_tdelta_mean.histogram.8',\n",
      "       'ioe_tdelta_mean.histogram.9', 'ioe_tdelta_mean.iq_range',\n",
      "       'ioe_tdelta_mean.kurtosis', 'ioe_tdelta_mean.max',\n",
      "       'ioe_tdelta_mean.mean', 'ioe_tdelta_mean.median', 'ioe_tdelta_mean.min',\n",
      "       'ioe_tdelta_mean.nanhistogram.0', 'ioe_tdelta_mean.nanhistogram.1',\n",
      "       'ioe_tdelta_mean.nanhistogram.2', 'ioe_tdelta_mean.nanhistogram.3',\n",
      "       'ioe_tdelta_mean.nanhistogram.4', 'ioe_tdelta_mean.nanhistogram.5',\n",
      "       'ioe_tdelta_mean.nanhistogram.6', 'ioe_tdelta_mean.nanhistogram.7',\n",
      "       'ioe_tdelta_mean.nanhistogram.8', 'ioe_tdelta_mean.nanhistogram.9',\n",
      "       'ioe_tdelta_mean.naniq_range', 'ioe_tdelta_mean.nankurtosis',\n",
      "       'ioe_tdelta_mean.nanmax', 'ioe_tdelta_mean.nanmean',\n",
      "       'ioe_tdelta_mean.nanmedian', 'ioe_tdelta_mean.nanmin',\n",
      "       'ioe_tdelta_mean.nanpnorm', 'ioe_tdelta_mean.nanpowersum',\n",
      "       'ioe_tdelta_mean.nanquantiles.0', 'ioe_tdelta_mean.nanquantiles.1',\n",
      "       'ioe_tdelta_mean.nanquantiles.2', 'ioe_tdelta_mean.nanquantiles.3',\n",
      "       'ioe_tdelta_mean.nanquantiles.4', 'ioe_tdelta_mean.nanrange',\n",
      "       'ioe_tdelta_mean.nansd', 'ioe_tdelta_mean.nanskewness',\n",
      "       'ioe_tdelta_mean.nansum', 'ioe_tdelta_mean.nanvar',\n",
      "       'ioe_tdelta_mean.pnorm', 'ioe_tdelta_mean.powersum',\n",
      "       'ioe_tdelta_mean.quantiles.0', 'ioe_tdelta_mean.quantiles.1',\n",
      "       'ioe_tdelta_mean.quantiles.2', 'ioe_tdelta_mean.quantiles.3',\n",
      "       'ioe_tdelta_mean.quantiles.4', 'ioe_tdelta_mean.range',\n",
      "       'ioe_tdelta_mean.sd', 'ioe_tdelta_mean.skewness', 'ioe_tdelta_mean.sum',\n",
      "       'ioe_tdelta_mean.var', 'turning_points.nanrange',\n",
      "       'turning_points.range', 'turning_points_trend.nanrange',\n",
      "       'turning_points_trend.range'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Note: suspicious meta-feature with all missing value. Which is it?\n",
    "ind = (nan_count == data_train.shape[0]).to_numpy().nonzero()\n",
    "print(results_train.columns[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after dropping NaN column: (736, 3752)\n",
      "Dropped 1413 of 5165 meta-features (27.36% from the total).\n"
     ]
    }
   ],
   "source": [
    "results_train.dropna(axis=1, inplace=True)\n",
    "print(\"Train shape after dropping NaN column:\", results_train.shape)\n",
    "print(f\"Dropped {len(mtf_names) - results_train.shape[1]} of {len(mtf_names)} meta-features \"\n",
    "      f\"({100 * (1 - results_train.shape[1] / len(mtf_names)):.2f}% from the total).\")\n",
    "results_test = results_test.loc[:, results_train.columns]\n",
    "\n",
    "# Note: sanity check if the columns where dropped correctly\n",
    "assert np.all(results_train.columns == results_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pipeline: sklearn.pipeline.Pipeline,\n",
    "                 X_train: np.ndarray,\n",
    "                 X_test: np.ndarray,\n",
    "                 y_train: np.ndarray,\n",
    "                 y_test:np.ndarray) -> float:\n",
    "    pipeline.fit(results_train)\n",
    "    \n",
    "    X_subset_train = pipeline.transform(X_train)\n",
    "    X_subset_test = pipeline.transform(X_test)\n",
    "    \n",
    "    assert X_subset_train.shape[1] == X_subset_test.shape[1]\n",
    "    \n",
    "    # Note: sanity check if train project is zero-centered\n",
    "    assert np.allclose(X_subset_train.mean(axis=0), 0.0)\n",
    "\n",
    "    print(\"Train shape after PCA:\", X_subset_train.shape)\n",
    "    print(\"Test shape after PCA :\", X_subset_test.shape)\n",
    "    print(f\"Total of {X_subset_train.shape[1]} of {X_train.shape[1]} \"\n",
    "          \"dimensions kept for 95% variance explained \"\n",
    "          f\"(reduction of {100. * (1 - X_subset_train.shape[1] / X_train.shape[1]):.2f}%).\")\n",
    "    \n",
    "    rf = sklearn.ensemble.RandomForestClassifier(random_state=16)\n",
    "    rf.fit(X=X_subset_train, y=y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_subset_test)\n",
    "\n",
    "    # Note: since the test set is balanced, we can use the traditional accuracy\n",
    "    test_acc = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after PCA: (736, 248)\n",
      "Test shape after PCA : (184, 248)\n",
      "Total of 248 of 3752 dimensions kept for 95% variance explained (reduction of 93.39%).\n",
      "Expected accuracy by random guessing: 0.0217\n",
      "Test accuracy (pipeline A - StandardScaler): 0.6033\n"
     ]
    }
   ],
   "source": [
    "pipeline_a = sklearn.pipeline.Pipeline((\n",
    "    (\"zscore\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"pca\", sklearn.decomposition.PCA(n_components=0.95, random_state=16))\n",
    "))\n",
    "\n",
    "test_acc_a = get_accuracy(pipeline=pipeline_a,\n",
    "                          X_train=results_train.values,\n",
    "                          X_test=results_test.values,\n",
    "                          y_train=data_train.category.values,\n",
    "                          y_test=data_test.category.values)\n",
    "\n",
    "# This is equivalent of guessing only the majority class, which can be any class\n",
    "# in this case since the dataset is perfectly balanced\n",
    "print(f\"Expected accuracy by random guessing: {1 / data_test.category.unique().size:.4f}\")\n",
    "print(f\"Test accuracy (pipeline A - StandardScaler): {test_acc_a:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9f0baa0fe63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                           \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                           y_test=data_test.category.values)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# This is equivalent of guessing only the majority class, which can be any class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-500fca80f073>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(pipeline, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0my_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  y_test:np.ndarray) -> float:\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_subset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/ts-pymfe-tests/4_extracting_mtf_tsmfe/robust_sigmoid.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, _)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids_trad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miqr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids_robust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids_trad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m     \u001b[0mxfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "pipeline_b = sklearn.pipeline.Pipeline((\n",
    "    (\"robsigmoid\", robust_sigmoid.RobustSigmoid()),\n",
    "    (\"pca\", sklearn.decomposition.PCA(n_components=0.95, random_state=16))\n",
    "))\n",
    "\n",
    "test_acc_b = get_accuracy(pipeline=pipeline_b,\n",
    "                          X_train=results_train.values,\n",
    "                          X_test=results_test.values,\n",
    "                          y_train=data_train.category.values,\n",
    "                          y_test=data_test.category.values)\n",
    "\n",
    "# This is equivalent of guessing only the majority class, which can be any class\n",
    "# in this case since the dataset is perfectly balanced\n",
    "print(f\"Expected accuracy by random guessing: {1 / data_test.category.unique().size:.4f}\")\n",
    "print(f\"Test accuracy (pipeline B - RobustSigmoid) : {test_acc_b:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
