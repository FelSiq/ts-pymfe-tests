{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CompEngine dataset analysis\n",
    "## Analysis #4: Get TS-Pymfe meta-features accuracy\n",
    "\n",
    "**Project URL:** https://www.comp-engine.org/\n",
    "\n",
    "**Get data in:** https://www.comp-engine.org/#!browse\n",
    "\n",
    "**Date:** May 31 2020\n",
    "\n",
    "### Objectives:\n",
    "1. Extract the meta-features using the ts-pymfe from train and test data\n",
    "2. Drop metafeatures with NaN.\n",
    "3. Apply PCA in the train meta-dataset.\n",
    "4. Use a simple machine learning model to predict the test set.\n",
    "\n",
    "### Results (please check the analysis date):\n",
    "1. All metafeatures from all methods combined with all summary functions in pymfe were extracted from both train and test data. This totalizes ?? candidate meta-features.\n",
    "2. ??\n",
    "3. The next step is to apply PCA retaining 95% of variance explained by the original meta-features. Before applying PCA we need to choose a normalization strategy. Two methods were considered:\n",
    "    1. (Pipeline A) Standard Scaler (traditional standardization): ?? of ?? dimensions were kept. This corresponds to a dimension reduction of ??%.\n",
    "    2. (Pipeline B) Robust Sigmoid Scaler (see reference [1]): ?? of ?? dimensions were kept. This corresponds to a dimension reduction of ??%.\n",
    "4. Now it is time for some predictions. I'm using a sklearn RandomForestClassifier model with default hyper-parameters with a fixed random seed.\n",
    "    1. The expected accuracy of random guessing is 2.17%.\n",
    "    2. (Pipeline A) It was obtained an accuracy score of ??%.\n",
    "    3. (Pipeline B) It was obtained an accuracy score of ??%.\n",
    "    \n",
    "\n",
    "## references:\n",
    "\n",
    ".. [1] Fulcher, Ben D.  and Little, Max A.  and Jones, Nick S., \"Highly comparative time-series analysis: the empirical structure of time series and their methods\" (Supplemental material #1, page 11), Journal of The Royal Society Interface, 2013, doi: 10.1098/rsif.2013.0048, https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2013.0048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Ts-Pymfe core not implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab9bc50086b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrobust_sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsmfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documentos/ts-pymfe-tests/4_extracting_mtf_tsmfe/pymfe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ts-Pymfe core not implemented.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: Ts-Pymfe core not implemented."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import typing\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "\n",
    "import robust_sigmoid\n",
    "import pymfe.tsmfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: using only groups that has at least one meta-feature that can be extracted\n",
    "# from a unsupervised dataset\n",
    "groups = \"all\"\n",
    "summary = \"all\"\n",
    "\n",
    "extractor = pymfe.tsmfe.TSMFE(features=\"all\",\n",
    "                              summary=summary,\n",
    "                              groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../2_exploring_subsample/subsample_train.csv\", header=0, index_col=\"timeseries_id\")\n",
    "data_test = pd.read_csv(\"../2_exploring_subsample/subsample_test.csv\", header=0, index_col=\"timeseries_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_train.shape[0] > data_test.shape[0]\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: using at most the last 1024 observations of each time-series\n",
    "size_threshold = 1024\n",
    "\n",
    "# Number of iterations until to save results to .csv\n",
    "to_csv_it_num = 16\n",
    "\n",
    "# Note: using dummy data to get the metafeature names\n",
    "mtf_names = extractor.fit(np.arange(16).reshape(-1, 2),\n",
    "                          suppress_warnings=True).extract(suppress_warnings=True)[0]\n",
    "\n",
    "# Note: filepath to store the results\n",
    "filename_train = \"metafeatures_pymfe_train.csv\"\n",
    "filename_test = \"metafeatures_pymfe_test.csv\"\n",
    "\n",
    "def recover_data(filepath: str,\n",
    "                 index: typing.Collection[str],\n",
    "                 def_shape: typing.Tuple[int, int]) -> typing.Tuple[pd.DataFrame, int]:\n",
    "    \"\"\"Recover data from the previous experiment run.\"\"\"\n",
    "    filled_len = 0\n",
    "    \n",
    "    try:\n",
    "        results = pd.read_csv(filepath, index_col=0)\n",
    "        \n",
    "        assert results.shape == def_shape\n",
    "\n",
    "        # Note: find the index where the previous run was interrupted\n",
    "        while filled_len < results.shape[0] and not results.iloc[filled_len, :].isnull().all():\n",
    "            filled_len += 1\n",
    "\n",
    "    except (AssertionError, FileNotFoundError):\n",
    "        results = pd.DataFrame(index=index, columns=mtf_names)\n",
    "    \n",
    "    return results, filled_len\n",
    "\n",
    "\n",
    "results_train, start_ind_train = recover_data(filepath=filename_train,\n",
    "                                              index=data_train.index,\n",
    "                                              def_shape=(data_train.shape[0], len(mtf_names)))\n",
    "\n",
    "results_test, start_ind_test = recover_data(filepath=filename_test,\n",
    "                                            index=data_test.index,\n",
    "                                            def_shape=(data_test.shape[0], len(mtf_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert results_train.shape == (data_train.shape[0], len(mtf_names))\n",
    "assert results_test.shape == (data_test.shape[0], len(mtf_names))\n",
    "\n",
    "print(\"Train start index:\", start_ind_train)\n",
    "print(\"Test start index:\", start_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of candidate meta-features per dataset:\", len(mtf_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metafeatures(data: pd.DataFrame, results: pd.DataFrame, start_ind: int, output_file: str) -> None:\n",
    "    print(f\"Starting extraction from index {start_ind}...\")\n",
    "    for i, (cls, _, vals) in enumerate(data.iloc[start_ind:, :].values, start_ind):\n",
    "        ts = np.asarray(vals.split(\",\")[-size_threshold:], dtype=float)\n",
    "        extractor.fit(ts_embed, suppress_warnings=True)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            res = extractor.extract(suppress_warnings=True)\n",
    "        \n",
    "        results.iloc[i, :] = res[1]\n",
    "\n",
    "        if i % to_csv_it_num == 0:\n",
    "            results.to_csv(output_file)\n",
    "            print(f\"Saved results at index {i} in file {output_file}.\")\n",
    "    \n",
    "    results.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_metafeatures(data=data_train,\n",
    "                     results=results_train,\n",
    "                     start_ind=start_ind_train,\n",
    "                     output_file=filename_train)\n",
    "\n",
    "extract_metafeatures(data=data_test,\n",
    "                     results=results_test,\n",
    "                     start_ind=start_ind_test,\n",
    "                     output_file=filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: analysing the NaN count.\n",
    "nan_count = results_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_nan_count = nan_count.iloc[nan_count.to_numpy().nonzero()].value_counts()\n",
    "pd_nan_count = pd.concat([pd_nan_count, pd_nan_count / results_train.shape[1]], axis=1)\n",
    "pd_nan_count = pd_nan_count.rename(columns={0: \"Number of meta-features\", 1: \"Proportion of meta-features\"})\n",
    "pd_nan_count.index =  map(\"{} (missing on {:.2f}% of all train time-series)\".format, pd_nan_count.index, 100. * pd_nan_count.index / results_train.shape[0])\n",
    "pd_nan_count.index.name = \"Missing values count\"\n",
    "pd_nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: suspicious meta-feature with all missing value. Which is it?\n",
    "ind = (nan_count == data_train.shape[0]).to_numpy().nonzero()\n",
    "print(results_train.columns[ind])\n",
    "\n",
    "# Note afterwards: the result (\"num_to_cat\") seems reasonable, since no\n",
    "# time-series should have categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train.dropna(axis=1, inplace=True)\n",
    "print(\"Train shape after dropping NaN column:\", results_train.shape)\n",
    "print(f\"Dropped {len(mtf_names) - results_train.shape[1]} of {len(mtf_names)} meta-features \"\n",
    "      f\"({100 * (1 - results_train.shape[1] / len(mtf_names)):.2f}% from the total).\")\n",
    "results_test = results_test.loc[:, results_train.columns]\n",
    "\n",
    "# Note: sanity check if the columns where dropped correctly\n",
    "assert np.all(results_train.columns == results_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pipeline: sklearn.pipeline.Pipeline,\n",
    "                 X_train: np.ndarray,\n",
    "                 X_test: np.ndarray,\n",
    "                 y_train: np.ndarray,\n",
    "                 y_test:np.ndarray) -> float:\n",
    "    pipeline.fit(results_train)\n",
    "    \n",
    "    X_subset_train = pipeline.transform(X_train)\n",
    "    X_subset_test = pipeline.transform(X_test)\n",
    "    \n",
    "    assert X_subset_train.shape[1] == X_subset_test.shape[1]\n",
    "    \n",
    "    # Note: sanity check if train project is zero-centered\n",
    "    assert np.allclose(X_subset_train.mean(axis=0), 0.0)\n",
    "\n",
    "    print(\"Train shape after PCA:\", X_subset_train.shape)\n",
    "    print(\"Test shape after PCA :\", X_subset_test.shape)\n",
    "    print(f\"Total of {X_subset_train.shape[1]} of {X_train.shape[1]} \"\n",
    "          \"dimensions kept for 95% variance explained \"\n",
    "          f\"(reduction of {100. * (1 - X_subset_train.shape[1] / X_train.shape[1]):.2f}%).\")\n",
    "    \n",
    "    rf = sklearn.ensemble.RandomForestClassifier(random_state=16)\n",
    "    rf.fit(X=X_subset_train, y=y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_subset_test)\n",
    "\n",
    "    # Note: since the test set is balanced, we can use the traditional accuracy\n",
    "    test_acc = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_a = sklearn.pipeline.Pipeline((\n",
    "    (\"zscore\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"pca\", sklearn.decomposition.PCA(n_components=0.95, random_state=16))\n",
    "))\n",
    "\n",
    "test_acc_a = get_accuracy(pipeline=pipeline_a,\n",
    "                          X_train=results_train.values,\n",
    "                          X_test=results_test.values,\n",
    "                          y_train=data_train.category.values,\n",
    "                          y_test=data_test.category.values)\n",
    "\n",
    "# This is equivalent of guessing only the majority class, which can be any class\n",
    "# in this case since the dataset is perfectly balanced\n",
    "print(f\"Expected accuracy by random guessing: {1 / data_test.category.unique().size:.4f}\")\n",
    "print(f\"Test accuracy (pipeline A - StandardScaler): {test_acc_a:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_b = sklearn.pipeline.Pipeline((\n",
    "    (\"robsigmoid\", robust_sigmoid.RobustSigmoid()),\n",
    "    (\"pca\", sklearn.decomposition.PCA(n_components=0.95, random_state=16))\n",
    "))\n",
    "\n",
    "test_acc_b = get_accuracy(pipeline=pipeline_b,\n",
    "                          X_train=results_train.values,\n",
    "                          X_test=results_test.values,\n",
    "                          y_train=data_train.category.values,\n",
    "                          y_test=data_test.category.values)\n",
    "\n",
    "# This is equivalent of guessing only the majority class, which can be any class\n",
    "# in this case since the dataset is perfectly balanced\n",
    "print(f\"Expected accuracy by random guessing: {1 / data_test.category.unique().size:.4f}\")\n",
    "print(f\"Test accuracy (pipeline B - RobustSigmoid) : {test_acc_b:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
